#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Faster-Whisperå­—å¹•ç”ŸæˆæœåŠ¡å™¨
ä½¿ç”¨faster-whisperåº“ï¼Œæ›´ç¨³å®šï¼Œä¾èµ–æ›´å°‘
"""

try:
    from faster_whisper import WhisperModel
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False

import tempfile
import os
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
model = None

def load_faster_whisper_model(model_size="small"):
    """åŠ è½½Faster-Whisperæ¨¡å‹"""
    global model
    try:
        logger.info(f"Loading Faster-Whisper model: {model_size}")
        model = WhisperModel(model_size, device="cpu", compute_type="int8")
        logger.info("Faster-Whisper model loaded successfully")
        return True
    except Exception as e:
        logger.error(f"Failed to load model: {e}")
        return False

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model is not None,
        'version': 'faster_whisper',
        'available': FASTER_WHISPER_AVAILABLE
    })

@app.route('/transcribe', methods=['POST'])
def transcribe_audio():
    """éŸ³é¢‘è½¬å½•æ¥å£"""
    try:
        if not FASTER_WHISPER_AVAILABLE:
            return jsonify({'error': 'faster-whisper not installed'}), 500
            
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if model is None:
            return jsonify({'error': 'Whisper model not loaded'}), 500
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ–‡ä»¶
        if 'audio' not in request.files:
            return jsonify({'error': 'No audio file provided'}), 400
        
        audio_file = request.files['audio']
        if audio_file.filename == '':
            return jsonify({'error': 'Empty filename'}), 400
        
        # è·å–å‚æ•°
        language = request.form.get('language', 'en')
        
        logger.info(f"Starting transcription: {audio_file.filename}")
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            audio_file.save(tmp_file.name)
            tmp_filename = tmp_file.name
        
        try:
            # ä½¿ç”¨Faster-Whisperè½¬å½•
            logger.info("Running Faster-Whisper transcription...")
            segments, info = model.transcribe(tmp_filename, language=language)
            
            # å¤„ç†ç»“æœ
            processed_segments = []
            full_text = ""
            
            for segment in segments:
                text = segment.text.strip()
                if text:
                    processed_segments.append({
                        'start': segment.start,
                        'end': segment.end,
                        'text': text
                    })
                    full_text += text + " "
            
            logger.info(f"Transcription completed, found {len(processed_segments)} segments")
            
            result = {
                'text': full_text.strip(),
                'language': info.language,
                'segments': processed_segments
            }
            
            return jsonify({
                'success': True,
                'result': result
            })
            
        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return jsonify({'error': f'Transcription failed: {str(e)}'}), 500
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(tmp_filename)
            except:
                pass
    
    except Exception as e:
        logger.error(f"Request processing error: {e}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸš€ Faster-Whisper AI Server")
    print("=" * 50)
    
    if not FASTER_WHISPER_AVAILABLE:
        print("âŒ faster-whisper not installed")
        print("Please run: pip install faster-whisper")
        exit(1)
    
    # å¯åŠ¨æ—¶åŠ è½½é»˜è®¤æ¨¡å‹
    print("Loading Faster-Whisper model...")
    if load_faster_whisper_model("small"):
        print("âœ… Faster-Whisper model loaded successfully")
    else:
        print("âŒ Failed to load Faster-Whisper model")
        exit(1)
    
    print("ğŸš€ Starting server...")
    print("ğŸ“¡ API URL: http://localhost:5000")
    print("=" * 50)
    
    # å¯åŠ¨FlaskæœåŠ¡å™¨
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False,
        threaded=True
    )
